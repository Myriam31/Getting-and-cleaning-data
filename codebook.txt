## Codebook

Original dataset: 
==================================================================
Human Activity Recognition Using Smartphones Dataset
Version 1.0
Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
Smartlab - Non Linear Complex Systems Laboratory
DITEN - Universit√† degli Studi di Genova.
Via Opera Pia 11A, I-16145, Genoa, Italy.
activityrecognition@smartlab.ws
www.smartlab.ws


License acknowledgement:
==================================================================
[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. 
Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine.
International Workshop of Ambient Assisted Living (IWAAL 2012).  Vitoria-Gasteiz, Spain. Dec 2012. 
This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed 
to the authors or their institutions for its use or misuse. Any commercial use is prohibited.


Codebook:
===================================================================
The original data was transformed using run_analysis script and a final table called tidysummary.txt was 
created.

Table contains a row for each activity and each subject for each of the original features that had a mean 
or a standard deviation associated with it.
There are 30 subjects or volunteers, six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING,
LAYING).

Column descriptions
Subject: Id for the volunteer (1 through 30)
Activity_label: Type of the activity performed by the volunteer
	WALKING
	WALKING_DOWNSTAIRS
	SITTING
	STANDING
	LAYING
Variables: there are 73 numerical variables collected from the smartphone. 
Each variable has been averaged over subject and activity_label 
	tBodyAcc mean   X
	tBodyAcc mean   Y
	tBodyAcc mean   Z
	tGravityAcc mean   X
	tGravityAcc mean   Y
	tGravityAcc mean   Z
	tBodyAccJerk mean   X
	tBodyAccJerk mean   Y
	tBodyAccJerk mean   Z
	tBodyGyro mean   X
	tBodyGyro mean   Y
	tBodyGyro mean   Z
	tBodyGyroJerk mean   X
	tBodyGyroJerk mean   Y
	tBodyGyroJerk mean   Z
	tBodyAccMag mean
	tGravityAccMag mean
	tBodyAccJerkMag mean
	tBodyGyroMag mean
	tBodyGyroJerkMag mean
	fBodyAcc mean   X
	fBodyAcc mean   Y
	fBodyAcc mean   Z
	fBodyAccJerk mean   X
	fBodyAccJerk mean   Y
	fBodyAccJerk mean   Z
	fBodyGyro mean   X
	fBodyGyro mean   Y
	fBodyGyro mean   Z
	fBodyAccMag mean
	fBodyBodyAccJerkMag mean
	fBodyBodyGyroMag mean
	fBodyBodyGyroJerkMag mean
	angle tBodyAccMean gravity
	angle tBodyAccJerkMean  gravityMean
	angle tBodyGyroMean gravityMean
	angle tBodyGyroJerkMean gravityMean
	angle X gravityMean
	angle Y gravityMean
	angle Z gravityMean
	tBodyAcc std   X
	tBodyAcc std   Y
	tBodyAcc std   Z
	tGravityAcc std   X
	tGravityAcc std   Y
	tGravityAcc std   Z
	tBodyAccJerk std   X
	tBodyAccJerk std   Y
	tBodyAccJerk std   Z
	tBodyGyro std   X
	tBodyGyro std   Y
	tBodyGyro std   Z
	tBodyGyroJerk std   X
	tBodyGyroJerk std   Y
	tBodyGyroJerk std   Z
	tBodyAccMag std
	tGravityAccMag std
	tBodyAccJerkMag std
	tBodyGyroMag std
	tBodyGyroJerkMag std
	fBodyAcc std   X
	fBodyAcc std   Y
	fBodyAcc std   Z
	fBodyAccJerk std   X
	fBodyAccJerk std   Y
	fBodyAccJerk std   Z
	fBodyGyro std   X
	fBodyGyro std   Y
	fBodyGyro std   Z
	fBodyAccMag std
	fBodyBodyAccJerkMag std
	fBodyBodyGyroMag std
	fBodyBodyGyroJerkMag std



More details: 
==================================================================
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. 
Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) 
wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, 
we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. 
The volunteers are the subjects,
the activity_label refers to the type of activity the subject performed

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in 
fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, 
which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body 
acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a 
filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating 
variables from the time and frequency domain. See 'features_info.txt' for more details. 

For each record it is provided:
======================================

- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. 
- Its activity label. 
- An identifier of the subject who carried out the experiment.

The dataset includes the following features:
=========================================

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. 
These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. 
Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. 
Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ)
using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ).
Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm  (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing 
fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. 
(Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate Mean value ( mean() ) and standard deviation ( std() ) for the 
variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:
gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

There are no Standard deviation for those vectors

The data was summarized by activity type and subject
